{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aquatic-disco",
   "metadata": {},
   "source": [
    "# Wild Edible Food Application with Image Recognition \n",
    "\n",
    "#### A CNN trained using the swedish leaf dataset to classify images from a set of 15 species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "honest-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import random\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#datasetDir = r\"D:\\Uni_Work\\Third Year\\Advanced Intelligent Systems\\TensorFlow\\swedishLeafDataset\"\n",
    "#testDir = r\"D:\\Uni_Work\\Third Year\\Advanced Intelligent Systems\\TensorFlow\\data\\test\"\n",
    "#ext_test_data = r\"D:\\Uni_Work\\Third Year\\Advanced Intelligent Systems\\TensorFlow\\data\\External_test\"\n",
    "cwd = os.getcwd()\n",
    "datasetDir = cwd +\"\\data\\\\train\"\n",
    "testDir = cwd + \"\\data\\\\test\"\n",
    "\n",
    "class_names = ['leaf1', 'leaf2', 'leaf3', 'leaf4', 'leaf5',\n",
    "               'leaf6', 'leaf7', 'leaf8', 'leaf9', 'leaf10',\n",
    "               'leaf11', 'leaf12', 'leaf13', 'leaf14', 'leaf15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "uniform-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "test_data = []\n",
    "IMG_SIZE = 50\n",
    "\n",
    "\n",
    "def create_training_data():\n",
    "    for category in class_names:\n",
    "        path = os.path.join(datasetDir, category)\n",
    "        class_num = class_names.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE) #\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "\n",
    "def create_test_data():\n",
    "    for category in class_names:\n",
    "        path = os.path.join(testDir)\n",
    "        class_num = class_names.index(category)\n",
    "        for img in range(0, 7):\n",
    "            file_name = \"l\" + str(class_names.index(category)+1) + \"nr00\" + str(img + 1) + \".TIF\"\n",
    "            img_array = cv2.imread(os.path.join(path, file_name), cv2.IMREAD_GRAYSCALE)\n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "            test_data.append([new_array, class_num])\n",
    "            \n",
    "create_training_data()\n",
    "create_test_data()\n",
    "random.shuffle(training_data)\n",
    "random.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "signed-needle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n",
    "for features, label in test_data:\n",
    "    X_test.append(features)\n",
    "    Y_test.append(label)\n",
    "X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "X = X.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "X /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "Y = to_categorical(Y, 15)\n",
    "Y_test = to_categorical(Y_test, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cordless-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_test_data = cwd + \"\\data\\\\External_test\"\n",
    "ext_test = []\n",
    "def ext_create_test_data():\n",
    "    for category in class_names:\n",
    "        path = os.path.join(ext_test_data)\n",
    "        class_num = class_names.index(category)\n",
    "        for img in range(0, 2):\n",
    "            file_name = \"exl\" + str(class_names.index(category)+1) + \"nr00\" + str(img + 1) + \".JPG\"\n",
    "            img_array = cv2.imread(os.path.join(path, file_name), cv2.IMREAD_GRAYSCALE)\n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "            ext_test.append([new_array, class_num])\n",
    "            \n",
    "ext_create_test_data()\n",
    "#random.shuffle(ext_test())\n",
    "X_ext = []\n",
    "Y_ext = []\n",
    "for features, label in ext_test:\n",
    "    X_ext.append(features)\n",
    "    Y_ext.append(label)\n",
    "X_ext = np.array(X_ext).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "Y_ext = to_categorical(Y_ext, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "corrected-consideration",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "32/32 [==============================] - 2s 70ms/step - loss: 2.2944 - accuracy: 0.3069 - recall_1: 0.0431 - precision_1: 0.9565\n",
      "Epoch 2/15\n",
      "32/32 [==============================] - 2s 69ms/step - loss: 1.2133 - accuracy: 0.6167 - recall_1: 0.3902 - precision_1: 0.8172\n",
      "Epoch 3/15\n",
      "32/32 [==============================] - 2s 70ms/step - loss: 0.7059 - accuracy: 0.7755 - recall_1: 0.6706 - precision_1: 0.8724\n",
      "Epoch 4/15\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.5306 - accuracy: 0.8353 - recall_1: 0.7706 - precision_1: 0.8983\n",
      "Epoch 5/15\n",
      "32/32 [==============================] - 2s 72ms/step - loss: 0.4337 - accuracy: 0.8618 - recall_1: 0.8157 - precision_1: 0.9043\n",
      "Epoch 6/15\n",
      "32/32 [==============================] - 2s 69ms/step - loss: 0.3464 - accuracy: 0.8941 - recall_1: 0.8490 - precision_1: 0.9342\n",
      "Epoch 7/15\n",
      "32/32 [==============================] - 2s 72ms/step - loss: 0.2708 - accuracy: 0.9206 - recall_1: 0.8873 - precision_1: 0.9417\n",
      "Epoch 8/15\n",
      "32/32 [==============================] - 2s 72ms/step - loss: 0.2460 - accuracy: 0.9186 - recall_1: 0.9000 - precision_1: 0.9406\n",
      "Epoch 9/15\n",
      "32/32 [==============================] - 2s 70ms/step - loss: 0.1702 - accuracy: 0.9471 - recall_1: 0.9324 - precision_1: 0.9626\n",
      "Epoch 10/15\n",
      "32/32 [==============================] - 2s 71ms/step - loss: 0.1395 - accuracy: 0.9471 - recall_1: 0.9412 - precision_1: 0.9600\n",
      "Epoch 11/15\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.1261 - accuracy: 0.9618 - recall_1: 0.9431 - precision_1: 0.9668\n",
      "Epoch 12/15\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.1056 - accuracy: 0.9667 - recall_1: 0.9618 - precision_1: 0.9732\n",
      "Epoch 13/15\n",
      "32/32 [==============================] - 2s 71ms/step - loss: 0.0981 - accuracy: 0.9735 - recall_1: 0.9686 - precision_1: 0.9811\n",
      "Epoch 14/15\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.0752 - accuracy: 0.9833 - recall_1: 0.9716 - precision_1: 0.9890\n",
      "Epoch 15/15\n",
      "32/32 [==============================] - 2s 71ms/step - loss: 0.0540 - accuracy: 0.9863 - recall_1: 0.9843 - precision_1: 0.9901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x222d3481b50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(IMG_SIZE, IMG_SIZE, 1)))#, data_format=\"channels_first\"\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(15, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "model.fit(X, Y, batch_size=32, epochs=15, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "determined-combat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.970278024673462, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752]\n",
      "[0.011373880319297314, 0.9990196228027344, 0.9970588088035583, 0.9990176558494568]\n",
      "[2864.52197265625, 0.20000000298023224, 0.20000000298023224, 0.20000000298023224]\n",
      "['loss', 'accuracy', 'recall_1', 'precision_1']\n"
     ]
    }
   ],
   "source": [
    "#from sklearn import classification_report\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score2 = model.evaluate(X, Y, verbose=0)\n",
    "print(score)\n",
    "print(score2)\n",
    "score3 = model.evaluate(X_ext, Y_ext, verbose=0)\n",
    "print(score3)\n",
    "\n",
    "#print(classification_report(Y_ext, model.predict(X_ext)))\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "coral-yield",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mping\n",
    "#imgPath = \"data/Percentage_Image/exl11nr002-Copy1.jpg\"\n",
    "imgPath = \"data/Percentage_Image/predict2.tif\"\n",
    "\n",
    "#img = image.load_img(imgPath, target_size=(50, 50))\n",
    "\n",
    "#img_array = image.img_to_array(img)\n",
    "#img_batch = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "#img_preprocessed = preprocess_input(img_batch)\n",
    "#print(img_preprocessed.shape)\n",
    "#prediction = model.predict(img_preprocessed)\n",
    "\n",
    "#img = image.load_img(imgPath, target_size=(50, 50))\n",
    "#plt.imshow(img)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 50\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "prediction = model.predict([prepare(imgPath)])\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "roman-centre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "leaf1\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare(imgPath)])\n",
    "print(prediction)\n",
    "print(class_names[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "israeli-chicken",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "leaf1\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare(\"data/Percentage_Image/predict1.jpg\")])\n",
    "print(prediction)\n",
    "print(class_names[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "shared-upset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "leaf1\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare(\"data/train/leaf7/L7nr067.tif\")])\n",
    "print(prediction)\n",
    "print(class_names[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "presidential-electronics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-0542ba187c18>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "leaf2\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_classes([prepare(\"data/train/leaf2/L2nr067.tif\")])\n",
    "print(class_names[int(prediction)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-lightning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
